{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51bf25f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "0    -0.089926  0.343874  0.176382  0.169358 -0.413337 -0.276315  0.188070   \n",
      "1     0.303261  0.084930  0.047369 -0.017244 -0.524733 -0.104934  0.335107   \n",
      "2    -0.274291  0.216801  0.029110  0.259279 -0.655594 -0.289643  0.073369   \n",
      "3     0.118676  0.095572  0.157358  0.225097 -0.632885 -0.125629  0.204013   \n",
      "4     0.298772  0.300674  0.366119 -0.022142 -0.748852 -0.035268  0.277504   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1121 -0.316305  0.126331  0.084587  0.099225 -0.503260 -0.062559  0.115574   \n",
      "1122 -0.342471  0.060391 -0.009947  0.156623 -0.511338 -0.070624  0.140290   \n",
      "1123 -0.379174  0.197136  0.149639  0.060261 -0.347212 -0.064022  0.119379   \n",
      "1124 -0.379726  0.075891  0.100093  0.118006 -0.429774 -0.140415  0.120826   \n",
      "1125 -0.279187  0.099571  0.229438  0.197775 -0.326235 -0.254882 -0.000509   \n",
      "\n",
      "       embed_7   embed_8   embed_9  ...  embed_376  embed_377  embed_378  \\\n",
      "0     0.094621  0.330203 -0.258730  ...  -0.230662   0.173143  -0.259786   \n",
      "1    -0.081476  0.213762 -0.105293  ...  -0.090271   0.129022  -0.008138   \n",
      "2     0.014463  0.104336 -0.014190  ...  -0.117493  -0.118993  -0.046860   \n",
      "3     0.074028  0.149310 -0.147779  ...  -0.100965   0.236099  -0.286450   \n",
      "4     0.075697  0.055439 -0.200804  ...  -0.230057   0.296528  -0.526185   \n",
      "...        ...       ...       ...  ...        ...        ...        ...   \n",
      "1121  0.012244  0.254925 -0.056957  ...  -0.316320   0.013955  -0.030025   \n",
      "1122  0.027731  0.275638 -0.068072  ...  -0.419794   0.061882  -0.190783   \n",
      "1123  0.019028  0.268377 -0.188386  ...  -0.354851   0.093440  -0.093673   \n",
      "1124  0.074879  0.154743 -0.030652  ...  -0.428964   0.052585  -0.172558   \n",
      "1125  0.034733  0.283212 -0.207798  ...  -0.275116  -0.012660   0.011353   \n",
      "\n",
      "      embed_379  embed_380  embed_381  embed_382  embed_383  output  \\\n",
      "0     -0.316996  -0.389919   0.105596   0.196438   0.117199     0.0   \n",
      "1     -0.220774  -0.021343  -0.029695   0.335977  -0.197539     0.0   \n",
      "2      0.010008  -0.118400  -0.085768   0.512956   0.023334     0.0   \n",
      "3     -0.130198  -0.051258  -0.047492   0.241473  -0.095162     0.0   \n",
      "4     -0.251471   0.196795  -0.101786   0.570922   0.007743     0.0   \n",
      "...         ...        ...        ...        ...        ...     ...   \n",
      "1121  -0.306975   0.139429  -0.256867   0.331288  -0.045333     5.0   \n",
      "1122  -0.323777   0.185546  -0.144995   0.347215  -0.024521     5.0   \n",
      "1123  -0.271739   0.042851  -0.143179   0.410811  -0.105163     5.0   \n",
      "1124  -0.218717   0.201938  -0.085569   0.345646  -0.032904     5.0   \n",
      "1125  -0.323538   0.055882   0.001314   0.474825  -0.055474     5.0   \n",
      "\n",
      "      Classification  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n",
      "...              ...  \n",
      "1121               1  \n",
      "1122               1  \n",
      "1123               1  \n",
      "1124               1  \n",
      "1125               1  \n",
      "\n",
      "[1126 rows x 386 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "data = pd.read_excel('training_mathbert.xlsx')\n",
    "\n",
    "# Create a new column 'Classification'\n",
    "data['Classification'] = (data['output'] >= 4).astype(int)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "618944d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_0</th>\n",
       "      <th>embed_1</th>\n",
       "      <th>embed_2</th>\n",
       "      <th>embed_3</th>\n",
       "      <th>embed_4</th>\n",
       "      <th>embed_5</th>\n",
       "      <th>embed_6</th>\n",
       "      <th>embed_7</th>\n",
       "      <th>embed_8</th>\n",
       "      <th>embed_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_375</th>\n",
       "      <th>embed_376</th>\n",
       "      <th>embed_377</th>\n",
       "      <th>embed_378</th>\n",
       "      <th>embed_379</th>\n",
       "      <th>embed_380</th>\n",
       "      <th>embed_381</th>\n",
       "      <th>embed_382</th>\n",
       "      <th>embed_383</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.089926</td>\n",
       "      <td>0.343874</td>\n",
       "      <td>0.176382</td>\n",
       "      <td>0.169358</td>\n",
       "      <td>-0.413337</td>\n",
       "      <td>-0.276315</td>\n",
       "      <td>0.188070</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>0.330203</td>\n",
       "      <td>-0.258730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272278</td>\n",
       "      <td>-0.230662</td>\n",
       "      <td>0.173143</td>\n",
       "      <td>-0.259786</td>\n",
       "      <td>-0.316996</td>\n",
       "      <td>-0.389919</td>\n",
       "      <td>0.105596</td>\n",
       "      <td>0.196438</td>\n",
       "      <td>0.117199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303261</td>\n",
       "      <td>0.084930</td>\n",
       "      <td>0.047369</td>\n",
       "      <td>-0.017244</td>\n",
       "      <td>-0.524733</td>\n",
       "      <td>-0.104934</td>\n",
       "      <td>0.335107</td>\n",
       "      <td>-0.081476</td>\n",
       "      <td>0.213762</td>\n",
       "      <td>-0.105293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310262</td>\n",
       "      <td>-0.090271</td>\n",
       "      <td>0.129022</td>\n",
       "      <td>-0.008138</td>\n",
       "      <td>-0.220774</td>\n",
       "      <td>-0.021343</td>\n",
       "      <td>-0.029695</td>\n",
       "      <td>0.335977</td>\n",
       "      <td>-0.197539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.274291</td>\n",
       "      <td>0.216801</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>0.259279</td>\n",
       "      <td>-0.655594</td>\n",
       "      <td>-0.289643</td>\n",
       "      <td>0.073369</td>\n",
       "      <td>0.014463</td>\n",
       "      <td>0.104336</td>\n",
       "      <td>-0.014190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464926</td>\n",
       "      <td>-0.117493</td>\n",
       "      <td>-0.118993</td>\n",
       "      <td>-0.046860</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>-0.118400</td>\n",
       "      <td>-0.085768</td>\n",
       "      <td>0.512956</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118676</td>\n",
       "      <td>0.095572</td>\n",
       "      <td>0.157358</td>\n",
       "      <td>0.225097</td>\n",
       "      <td>-0.632885</td>\n",
       "      <td>-0.125629</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.074028</td>\n",
       "      <td>0.149310</td>\n",
       "      <td>-0.147779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030543</td>\n",
       "      <td>-0.100965</td>\n",
       "      <td>0.236099</td>\n",
       "      <td>-0.286450</td>\n",
       "      <td>-0.130198</td>\n",
       "      <td>-0.051258</td>\n",
       "      <td>-0.047492</td>\n",
       "      <td>0.241473</td>\n",
       "      <td>-0.095162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298772</td>\n",
       "      <td>0.300674</td>\n",
       "      <td>0.366119</td>\n",
       "      <td>-0.022142</td>\n",
       "      <td>-0.748852</td>\n",
       "      <td>-0.035268</td>\n",
       "      <td>0.277504</td>\n",
       "      <td>0.075697</td>\n",
       "      <td>0.055439</td>\n",
       "      <td>-0.200804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149575</td>\n",
       "      <td>-0.230057</td>\n",
       "      <td>0.296528</td>\n",
       "      <td>-0.526185</td>\n",
       "      <td>-0.251471</td>\n",
       "      <td>0.196795</td>\n",
       "      <td>-0.101786</td>\n",
       "      <td>0.570922</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>-0.316305</td>\n",
       "      <td>0.126331</td>\n",
       "      <td>0.084587</td>\n",
       "      <td>0.099225</td>\n",
       "      <td>-0.503260</td>\n",
       "      <td>-0.062559</td>\n",
       "      <td>0.115574</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.254925</td>\n",
       "      <td>-0.056957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514027</td>\n",
       "      <td>-0.316320</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>-0.030025</td>\n",
       "      <td>-0.306975</td>\n",
       "      <td>0.139429</td>\n",
       "      <td>-0.256867</td>\n",
       "      <td>0.331288</td>\n",
       "      <td>-0.045333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>-0.342471</td>\n",
       "      <td>0.060391</td>\n",
       "      <td>-0.009947</td>\n",
       "      <td>0.156623</td>\n",
       "      <td>-0.511338</td>\n",
       "      <td>-0.070624</td>\n",
       "      <td>0.140290</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.275638</td>\n",
       "      <td>-0.068072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595396</td>\n",
       "      <td>-0.419794</td>\n",
       "      <td>0.061882</td>\n",
       "      <td>-0.190783</td>\n",
       "      <td>-0.323777</td>\n",
       "      <td>0.185546</td>\n",
       "      <td>-0.144995</td>\n",
       "      <td>0.347215</td>\n",
       "      <td>-0.024521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>-0.379174</td>\n",
       "      <td>0.197136</td>\n",
       "      <td>0.149639</td>\n",
       "      <td>0.060261</td>\n",
       "      <td>-0.347212</td>\n",
       "      <td>-0.064022</td>\n",
       "      <td>0.119379</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>0.268377</td>\n",
       "      <td>-0.188386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.517010</td>\n",
       "      <td>-0.354851</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>-0.093673</td>\n",
       "      <td>-0.271739</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>-0.143179</td>\n",
       "      <td>0.410811</td>\n",
       "      <td>-0.105163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>-0.379726</td>\n",
       "      <td>0.075891</td>\n",
       "      <td>0.100093</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>-0.429774</td>\n",
       "      <td>-0.140415</td>\n",
       "      <td>0.120826</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>0.154743</td>\n",
       "      <td>-0.030652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683223</td>\n",
       "      <td>-0.428964</td>\n",
       "      <td>0.052585</td>\n",
       "      <td>-0.172558</td>\n",
       "      <td>-0.218717</td>\n",
       "      <td>0.201938</td>\n",
       "      <td>-0.085569</td>\n",
       "      <td>0.345646</td>\n",
       "      <td>-0.032904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>-0.279187</td>\n",
       "      <td>0.099571</td>\n",
       "      <td>0.229438</td>\n",
       "      <td>0.197775</td>\n",
       "      <td>-0.326235</td>\n",
       "      <td>-0.254882</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.283212</td>\n",
       "      <td>-0.207798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574962</td>\n",
       "      <td>-0.275116</td>\n",
       "      <td>-0.012660</td>\n",
       "      <td>0.011353</td>\n",
       "      <td>-0.323538</td>\n",
       "      <td>0.055882</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.474825</td>\n",
       "      <td>-0.055474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1126 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
       "0    -0.089926  0.343874  0.176382  0.169358 -0.413337 -0.276315  0.188070   \n",
       "1     0.303261  0.084930  0.047369 -0.017244 -0.524733 -0.104934  0.335107   \n",
       "2    -0.274291  0.216801  0.029110  0.259279 -0.655594 -0.289643  0.073369   \n",
       "3     0.118676  0.095572  0.157358  0.225097 -0.632885 -0.125629  0.204013   \n",
       "4     0.298772  0.300674  0.366119 -0.022142 -0.748852 -0.035268  0.277504   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1121 -0.316305  0.126331  0.084587  0.099225 -0.503260 -0.062559  0.115574   \n",
       "1122 -0.342471  0.060391 -0.009947  0.156623 -0.511338 -0.070624  0.140290   \n",
       "1123 -0.379174  0.197136  0.149639  0.060261 -0.347212 -0.064022  0.119379   \n",
       "1124 -0.379726  0.075891  0.100093  0.118006 -0.429774 -0.140415  0.120826   \n",
       "1125 -0.279187  0.099571  0.229438  0.197775 -0.326235 -0.254882 -0.000509   \n",
       "\n",
       "       embed_7   embed_8   embed_9  ...  embed_375  embed_376  embed_377  \\\n",
       "0     0.094621  0.330203 -0.258730  ...  -0.272278  -0.230662   0.173143   \n",
       "1    -0.081476  0.213762 -0.105293  ...  -0.310262  -0.090271   0.129022   \n",
       "2     0.014463  0.104336 -0.014190  ...  -0.464926  -0.117493  -0.118993   \n",
       "3     0.074028  0.149310 -0.147779  ...  -0.030543  -0.100965   0.236099   \n",
       "4     0.075697  0.055439 -0.200804  ...  -0.149575  -0.230057   0.296528   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1121  0.012244  0.254925 -0.056957  ...  -0.514027  -0.316320   0.013955   \n",
       "1122  0.027731  0.275638 -0.068072  ...  -0.595396  -0.419794   0.061882   \n",
       "1123  0.019028  0.268377 -0.188386  ...  -0.517010  -0.354851   0.093440   \n",
       "1124  0.074879  0.154743 -0.030652  ...  -0.683223  -0.428964   0.052585   \n",
       "1125  0.034733  0.283212 -0.207798  ...  -0.574962  -0.275116  -0.012660   \n",
       "\n",
       "      embed_378  embed_379  embed_380  embed_381  embed_382  embed_383  \\\n",
       "0     -0.259786  -0.316996  -0.389919   0.105596   0.196438   0.117199   \n",
       "1     -0.008138  -0.220774  -0.021343  -0.029695   0.335977  -0.197539   \n",
       "2     -0.046860   0.010008  -0.118400  -0.085768   0.512956   0.023334   \n",
       "3     -0.286450  -0.130198  -0.051258  -0.047492   0.241473  -0.095162   \n",
       "4     -0.526185  -0.251471   0.196795  -0.101786   0.570922   0.007743   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1121  -0.030025  -0.306975   0.139429  -0.256867   0.331288  -0.045333   \n",
       "1122  -0.190783  -0.323777   0.185546  -0.144995   0.347215  -0.024521   \n",
       "1123  -0.093673  -0.271739   0.042851  -0.143179   0.410811  -0.105163   \n",
       "1124  -0.172558  -0.218717   0.201938  -0.085569   0.345646  -0.032904   \n",
       "1125   0.011353  -0.323538   0.055882   0.001314   0.474825  -0.055474   \n",
       "\n",
       "      Classification  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1121               1  \n",
       "1122               1  \n",
       "1123               1  \n",
       "1124               1  \n",
       "1125               1  \n",
       "\n",
       "[1126 rows x 385 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['output'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dc3a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame without 'output' column written to data1_no_output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'Average' is the column with values\n",
    "# Replace 'data' and 'Average' with your actual DataFrame and column names\n",
    "\n",
    "# Create a new column 'Classification' based on the conditions you mentioned\n",
    "data = pd.read_excel('training_mathbert.xlsx')\n",
    "data1 = pd.DataFrame(data)\n",
    "data1['Classification'] = (data1['output'] >= 4).astype(int)\n",
    "\n",
    "# Drop the 'output' column\n",
    "data1_no_output = data1.drop(['output'], axis=1)\n",
    "\n",
    "# Specify the file path where you want to save the Excel file\n",
    "excel_file_path = 'data1_no_output.xlsx'\n",
    "\n",
    "# Write the DataFrame without the 'output' column to an Excel file\n",
    "data1_no_output.to_excel(excel_file_path, index=False)\n",
    "\n",
    "# Print a message indicating the successful write\n",
    "print(f\"DataFrame without 'output' column written to {excel_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e9462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'Average' is the column with values\n",
    "# Replace 'data' and 'Average' with your actual DataFrame and column names\n",
    "\n",
    "# Create a new column 'Classification' based on the conditions you mentioned\n",
    "data = pd.read_excel('data1_no_output.xlsx')\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0617357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_0</th>\n",
       "      <th>embed_1</th>\n",
       "      <th>embed_2</th>\n",
       "      <th>embed_3</th>\n",
       "      <th>embed_4</th>\n",
       "      <th>embed_5</th>\n",
       "      <th>embed_6</th>\n",
       "      <th>embed_7</th>\n",
       "      <th>embed_8</th>\n",
       "      <th>embed_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_375</th>\n",
       "      <th>embed_376</th>\n",
       "      <th>embed_377</th>\n",
       "      <th>embed_378</th>\n",
       "      <th>embed_379</th>\n",
       "      <th>embed_380</th>\n",
       "      <th>embed_381</th>\n",
       "      <th>embed_382</th>\n",
       "      <th>embed_383</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.089926</td>\n",
       "      <td>0.343874</td>\n",
       "      <td>0.176382</td>\n",
       "      <td>0.169358</td>\n",
       "      <td>-0.413337</td>\n",
       "      <td>-0.276315</td>\n",
       "      <td>0.188070</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>0.330203</td>\n",
       "      <td>-0.258730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272278</td>\n",
       "      <td>-0.230662</td>\n",
       "      <td>0.173143</td>\n",
       "      <td>-0.259786</td>\n",
       "      <td>-0.316996</td>\n",
       "      <td>-0.389919</td>\n",
       "      <td>0.105596</td>\n",
       "      <td>0.196438</td>\n",
       "      <td>0.117199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303261</td>\n",
       "      <td>0.084930</td>\n",
       "      <td>0.047369</td>\n",
       "      <td>-0.017244</td>\n",
       "      <td>-0.524733</td>\n",
       "      <td>-0.104934</td>\n",
       "      <td>0.335107</td>\n",
       "      <td>-0.081476</td>\n",
       "      <td>0.213762</td>\n",
       "      <td>-0.105293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310262</td>\n",
       "      <td>-0.090271</td>\n",
       "      <td>0.129022</td>\n",
       "      <td>-0.008138</td>\n",
       "      <td>-0.220774</td>\n",
       "      <td>-0.021343</td>\n",
       "      <td>-0.029695</td>\n",
       "      <td>0.335977</td>\n",
       "      <td>-0.197539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.274291</td>\n",
       "      <td>0.216801</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>0.259279</td>\n",
       "      <td>-0.655594</td>\n",
       "      <td>-0.289643</td>\n",
       "      <td>0.073369</td>\n",
       "      <td>0.014463</td>\n",
       "      <td>0.104336</td>\n",
       "      <td>-0.014190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464926</td>\n",
       "      <td>-0.117493</td>\n",
       "      <td>-0.118993</td>\n",
       "      <td>-0.046860</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>-0.118400</td>\n",
       "      <td>-0.085768</td>\n",
       "      <td>0.512956</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118676</td>\n",
       "      <td>0.095572</td>\n",
       "      <td>0.157358</td>\n",
       "      <td>0.225097</td>\n",
       "      <td>-0.632885</td>\n",
       "      <td>-0.125629</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.074028</td>\n",
       "      <td>0.149310</td>\n",
       "      <td>-0.147779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030543</td>\n",
       "      <td>-0.100965</td>\n",
       "      <td>0.236099</td>\n",
       "      <td>-0.286450</td>\n",
       "      <td>-0.130198</td>\n",
       "      <td>-0.051258</td>\n",
       "      <td>-0.047492</td>\n",
       "      <td>0.241473</td>\n",
       "      <td>-0.095162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298772</td>\n",
       "      <td>0.300674</td>\n",
       "      <td>0.366119</td>\n",
       "      <td>-0.022142</td>\n",
       "      <td>-0.748852</td>\n",
       "      <td>-0.035268</td>\n",
       "      <td>0.277504</td>\n",
       "      <td>0.075697</td>\n",
       "      <td>0.055439</td>\n",
       "      <td>-0.200804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149575</td>\n",
       "      <td>-0.230057</td>\n",
       "      <td>0.296528</td>\n",
       "      <td>-0.526185</td>\n",
       "      <td>-0.251471</td>\n",
       "      <td>0.196795</td>\n",
       "      <td>-0.101786</td>\n",
       "      <td>0.570922</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>-0.316305</td>\n",
       "      <td>0.126331</td>\n",
       "      <td>0.084587</td>\n",
       "      <td>0.099225</td>\n",
       "      <td>-0.503260</td>\n",
       "      <td>-0.062559</td>\n",
       "      <td>0.115574</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.254925</td>\n",
       "      <td>-0.056957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514027</td>\n",
       "      <td>-0.316320</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>-0.030025</td>\n",
       "      <td>-0.306975</td>\n",
       "      <td>0.139429</td>\n",
       "      <td>-0.256867</td>\n",
       "      <td>0.331288</td>\n",
       "      <td>-0.045333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>-0.342471</td>\n",
       "      <td>0.060391</td>\n",
       "      <td>-0.009947</td>\n",
       "      <td>0.156623</td>\n",
       "      <td>-0.511338</td>\n",
       "      <td>-0.070624</td>\n",
       "      <td>0.140290</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.275638</td>\n",
       "      <td>-0.068072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595396</td>\n",
       "      <td>-0.419794</td>\n",
       "      <td>0.061882</td>\n",
       "      <td>-0.190783</td>\n",
       "      <td>-0.323777</td>\n",
       "      <td>0.185546</td>\n",
       "      <td>-0.144995</td>\n",
       "      <td>0.347215</td>\n",
       "      <td>-0.024521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>-0.379174</td>\n",
       "      <td>0.197136</td>\n",
       "      <td>0.149639</td>\n",
       "      <td>0.060261</td>\n",
       "      <td>-0.347212</td>\n",
       "      <td>-0.064022</td>\n",
       "      <td>0.119379</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>0.268377</td>\n",
       "      <td>-0.188386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.517010</td>\n",
       "      <td>-0.354851</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>-0.093673</td>\n",
       "      <td>-0.271739</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>-0.143179</td>\n",
       "      <td>0.410811</td>\n",
       "      <td>-0.105163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>-0.379726</td>\n",
       "      <td>0.075891</td>\n",
       "      <td>0.100093</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>-0.429774</td>\n",
       "      <td>-0.140415</td>\n",
       "      <td>0.120826</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>0.154743</td>\n",
       "      <td>-0.030652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683223</td>\n",
       "      <td>-0.428964</td>\n",
       "      <td>0.052585</td>\n",
       "      <td>-0.172558</td>\n",
       "      <td>-0.218717</td>\n",
       "      <td>0.201938</td>\n",
       "      <td>-0.085569</td>\n",
       "      <td>0.345646</td>\n",
       "      <td>-0.032904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>-0.279187</td>\n",
       "      <td>0.099571</td>\n",
       "      <td>0.229438</td>\n",
       "      <td>0.197775</td>\n",
       "      <td>-0.326235</td>\n",
       "      <td>-0.254882</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.283212</td>\n",
       "      <td>-0.207798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574962</td>\n",
       "      <td>-0.275116</td>\n",
       "      <td>-0.012660</td>\n",
       "      <td>0.011353</td>\n",
       "      <td>-0.323538</td>\n",
       "      <td>0.055882</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.474825</td>\n",
       "      <td>-0.055474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1126 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
       "0    -0.089926  0.343874  0.176382  0.169358 -0.413337 -0.276315  0.188070   \n",
       "1     0.303261  0.084930  0.047369 -0.017244 -0.524733 -0.104934  0.335107   \n",
       "2    -0.274291  0.216801  0.029110  0.259279 -0.655594 -0.289643  0.073369   \n",
       "3     0.118676  0.095572  0.157358  0.225097 -0.632885 -0.125629  0.204013   \n",
       "4     0.298772  0.300674  0.366119 -0.022142 -0.748852 -0.035268  0.277504   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1121 -0.316305  0.126331  0.084587  0.099225 -0.503260 -0.062559  0.115574   \n",
       "1122 -0.342471  0.060391 -0.009947  0.156623 -0.511338 -0.070624  0.140290   \n",
       "1123 -0.379174  0.197136  0.149639  0.060261 -0.347212 -0.064022  0.119379   \n",
       "1124 -0.379726  0.075891  0.100093  0.118006 -0.429774 -0.140415  0.120826   \n",
       "1125 -0.279187  0.099571  0.229438  0.197775 -0.326235 -0.254882 -0.000509   \n",
       "\n",
       "       embed_7   embed_8   embed_9  ...  embed_375  embed_376  embed_377  \\\n",
       "0     0.094621  0.330203 -0.258730  ...  -0.272278  -0.230662   0.173143   \n",
       "1    -0.081476  0.213762 -0.105293  ...  -0.310262  -0.090271   0.129022   \n",
       "2     0.014463  0.104336 -0.014190  ...  -0.464926  -0.117493  -0.118993   \n",
       "3     0.074028  0.149310 -0.147779  ...  -0.030543  -0.100965   0.236099   \n",
       "4     0.075697  0.055439 -0.200804  ...  -0.149575  -0.230057   0.296528   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1121  0.012244  0.254925 -0.056957  ...  -0.514027  -0.316320   0.013955   \n",
       "1122  0.027731  0.275638 -0.068072  ...  -0.595396  -0.419794   0.061882   \n",
       "1123  0.019028  0.268377 -0.188386  ...  -0.517010  -0.354851   0.093440   \n",
       "1124  0.074879  0.154743 -0.030652  ...  -0.683223  -0.428964   0.052585   \n",
       "1125  0.034733  0.283212 -0.207798  ...  -0.574962  -0.275116  -0.012660   \n",
       "\n",
       "      embed_378  embed_379  embed_380  embed_381  embed_382  embed_383  \\\n",
       "0     -0.259786  -0.316996  -0.389919   0.105596   0.196438   0.117199   \n",
       "1     -0.008138  -0.220774  -0.021343  -0.029695   0.335977  -0.197539   \n",
       "2     -0.046860   0.010008  -0.118400  -0.085768   0.512956   0.023334   \n",
       "3     -0.286450  -0.130198  -0.051258  -0.047492   0.241473  -0.095162   \n",
       "4     -0.526185  -0.251471   0.196795  -0.101786   0.570922   0.007743   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1121  -0.030025  -0.306975   0.139429  -0.256867   0.331288  -0.045333   \n",
       "1122  -0.190783  -0.323777   0.185546  -0.144995   0.347215  -0.024521   \n",
       "1123  -0.093673  -0.271739   0.042851  -0.143179   0.410811  -0.105163   \n",
       "1124  -0.172558  -0.218717   0.201938  -0.085569   0.345646  -0.032904   \n",
       "1125   0.011353  -0.323538   0.055882   0.001314   0.474825  -0.055474   \n",
       "\n",
       "      Classification  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1121               1  \n",
       "1122               1  \n",
       "1123               1  \n",
       "1124               1  \n",
       "1125               1  \n",
       "\n",
       "[1126 rows x 385 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64a8da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1126 entries, 0 to 1125\n",
      "Columns: 385 entries, embed_0 to Classification\n",
      "dtypes: float64(384), int64(1)\n",
      "memory usage: 3.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08b6d559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate Rows except first occurrence:\n",
      "       embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
      "61   -0.261571  0.232315  0.221707  0.257949 -0.315569 -0.104210  0.262651   \n",
      "93   -0.235472  0.204784  0.226201  0.204360 -0.316786 -0.111816  0.194260   \n",
      "108  -0.067757  0.352509  0.428942  0.074384 -0.352869  0.044036  0.277463   \n",
      "130  -0.157559  0.163577  0.013681 -0.154754 -0.342508 -0.141131  0.303059   \n",
      "138   0.046318  0.216393  0.398672  0.155976 -0.472235 -0.191005  0.240980   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1029 -0.298058  0.008406  0.308784  0.217234 -0.699521 -0.255603  0.056546   \n",
      "1052 -0.471224 -0.043846 -0.137504  0.232097 -0.484364 -0.069173 -0.054859   \n",
      "1053 -0.471224 -0.043846 -0.137504  0.232097 -0.484364 -0.069173 -0.054859   \n",
      "1099 -0.023780  0.338453 -0.018280  0.198248 -0.692947 -0.342627  0.050847   \n",
      "1102 -0.361707  0.397077  0.191398  0.374314 -0.549473 -0.098338  0.629249   \n",
      "\n",
      "       embed_7   embed_8   embed_9  ...  embed_375  embed_376  embed_377  \\\n",
      "61    0.056236  0.263768 -0.006976  ...   0.009995  -0.004963  -0.095912   \n",
      "93    0.042793  0.163850 -0.072916  ...  -0.067767   0.016180  -0.006527   \n",
      "108   0.042857  0.049501  0.039289  ...  -0.239922   0.138692  -0.062138   \n",
      "130   0.042999  0.070868  0.053267  ...  -0.262721   0.027404  -0.197376   \n",
      "138  -0.021938  0.119557 -0.031701  ...  -0.330306  -0.054209  -0.203161   \n",
      "...        ...       ...       ...  ...        ...        ...        ...   \n",
      "1029  0.059297  0.175501 -0.064462  ...  -0.351159   0.008233  -0.004463   \n",
      "1052  0.018651  0.062980  0.071895  ...  -0.330481  -0.115017  -0.081841   \n",
      "1053  0.018651  0.062980  0.071895  ...  -0.330481  -0.115017  -0.081841   \n",
      "1099  0.016600  0.333190 -0.153251  ...  -0.308145  -0.248092  -0.297564   \n",
      "1102  0.137295  0.267895 -0.148661  ...  -0.403617   0.086872   0.174472   \n",
      "\n",
      "      embed_378  embed_379  embed_380  embed_381  embed_382  embed_383  \\\n",
      "61    -0.240983  -0.345900  -0.307155   0.163312  -0.061115   0.155244   \n",
      "93    -0.272607  -0.357924  -0.294247   0.092384  -0.081213   0.104344   \n",
      "108    0.239176  -0.139984  -0.270310   0.117803   0.371119   0.039776   \n",
      "130    0.204078  -0.247948  -0.387029  -0.058164   0.174222   0.017072   \n",
      "138    0.121323   0.046040  -0.533603  -0.041927   0.658331  -0.108952   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "1029  -0.067152  -0.168660  -0.156903  -0.148809   0.168174  -0.199077   \n",
      "1052  -0.110433  -0.367676  -0.230969   0.059845  -0.073676  -0.125429   \n",
      "1053  -0.110433  -0.367676  -0.230969   0.059845  -0.073676  -0.125429   \n",
      "1099  -0.135153  -0.238440   0.032245  -0.020174   0.394594   0.069252   \n",
      "1102  -0.091440  -0.316273  -0.589970   0.045557   0.234508  -0.135141   \n",
      "\n",
      "      Classification  \n",
      "61                 0  \n",
      "93                 0  \n",
      "108                0  \n",
      "130                0  \n",
      "138                0  \n",
      "...              ...  \n",
      "1029               1  \n",
      "1052               1  \n",
      "1053               1  \n",
      "1099               1  \n",
      "1102               1  \n",
      "\n",
      "[92 rows x 385 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicates = df[df.duplicated()]\n",
    " \n",
    "# Displaying the duplicate rows\n",
    "print(\"Duplicate Rows except first occurrence:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff96765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embed_0           0\n",
       "embed_1           0\n",
       "embed_2           0\n",
       "embed_3           0\n",
       "embed_4           0\n",
       "                 ..\n",
       "embed_380         0\n",
       "embed_381         0\n",
       "embed_382         0\n",
       "embed_383         0\n",
       "Classification    0\n",
       "Length: 385, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bf09086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    " \n",
    "# Drop duplicate rows except for the first occurrence\n",
    "df = df.drop_duplicates(keep='first')\n",
    " \n",
    "# Save the DataFrame without duplicates to an Excel file\n",
    "df.to_excel('no_duplicates.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3694e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'Average' is the column with values\n",
    "# Replace 'data' and 'Average' with your actual DataFrame and column names\n",
    "\n",
    "# Create a new column 'Classification' based on the conditions you mentioned\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63e8bdb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_0</th>\n",
       "      <th>embed_1</th>\n",
       "      <th>embed_2</th>\n",
       "      <th>embed_3</th>\n",
       "      <th>embed_4</th>\n",
       "      <th>embed_5</th>\n",
       "      <th>embed_6</th>\n",
       "      <th>embed_7</th>\n",
       "      <th>embed_8</th>\n",
       "      <th>embed_9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_375</th>\n",
       "      <th>embed_376</th>\n",
       "      <th>embed_377</th>\n",
       "      <th>embed_378</th>\n",
       "      <th>embed_379</th>\n",
       "      <th>embed_380</th>\n",
       "      <th>embed_381</th>\n",
       "      <th>embed_382</th>\n",
       "      <th>embed_383</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.089926</td>\n",
       "      <td>0.343874</td>\n",
       "      <td>0.176382</td>\n",
       "      <td>0.169358</td>\n",
       "      <td>-0.413337</td>\n",
       "      <td>-0.276315</td>\n",
       "      <td>0.188070</td>\n",
       "      <td>0.094621</td>\n",
       "      <td>0.330203</td>\n",
       "      <td>-0.258730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.272278</td>\n",
       "      <td>-0.230662</td>\n",
       "      <td>0.173143</td>\n",
       "      <td>-0.259786</td>\n",
       "      <td>-0.316996</td>\n",
       "      <td>-0.389919</td>\n",
       "      <td>0.105596</td>\n",
       "      <td>0.196438</td>\n",
       "      <td>0.117199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303261</td>\n",
       "      <td>0.084930</td>\n",
       "      <td>0.047369</td>\n",
       "      <td>-0.017244</td>\n",
       "      <td>-0.524733</td>\n",
       "      <td>-0.104934</td>\n",
       "      <td>0.335107</td>\n",
       "      <td>-0.081476</td>\n",
       "      <td>0.213762</td>\n",
       "      <td>-0.105293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310262</td>\n",
       "      <td>-0.090271</td>\n",
       "      <td>0.129022</td>\n",
       "      <td>-0.008138</td>\n",
       "      <td>-0.220774</td>\n",
       "      <td>-0.021343</td>\n",
       "      <td>-0.029695</td>\n",
       "      <td>0.335977</td>\n",
       "      <td>-0.197539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.274291</td>\n",
       "      <td>0.216801</td>\n",
       "      <td>0.029110</td>\n",
       "      <td>0.259279</td>\n",
       "      <td>-0.655594</td>\n",
       "      <td>-0.289643</td>\n",
       "      <td>0.073369</td>\n",
       "      <td>0.014463</td>\n",
       "      <td>0.104336</td>\n",
       "      <td>-0.014190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.464926</td>\n",
       "      <td>-0.117493</td>\n",
       "      <td>-0.118993</td>\n",
       "      <td>-0.046860</td>\n",
       "      <td>0.010008</td>\n",
       "      <td>-0.118400</td>\n",
       "      <td>-0.085768</td>\n",
       "      <td>0.512956</td>\n",
       "      <td>0.023334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118676</td>\n",
       "      <td>0.095572</td>\n",
       "      <td>0.157358</td>\n",
       "      <td>0.225097</td>\n",
       "      <td>-0.632885</td>\n",
       "      <td>-0.125629</td>\n",
       "      <td>0.204013</td>\n",
       "      <td>0.074028</td>\n",
       "      <td>0.149310</td>\n",
       "      <td>-0.147779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030543</td>\n",
       "      <td>-0.100965</td>\n",
       "      <td>0.236099</td>\n",
       "      <td>-0.286450</td>\n",
       "      <td>-0.130198</td>\n",
       "      <td>-0.051258</td>\n",
       "      <td>-0.047492</td>\n",
       "      <td>0.241473</td>\n",
       "      <td>-0.095162</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.298772</td>\n",
       "      <td>0.300674</td>\n",
       "      <td>0.366119</td>\n",
       "      <td>-0.022142</td>\n",
       "      <td>-0.748852</td>\n",
       "      <td>-0.035268</td>\n",
       "      <td>0.277504</td>\n",
       "      <td>0.075697</td>\n",
       "      <td>0.055439</td>\n",
       "      <td>-0.200804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149575</td>\n",
       "      <td>-0.230057</td>\n",
       "      <td>0.296528</td>\n",
       "      <td>-0.526185</td>\n",
       "      <td>-0.251471</td>\n",
       "      <td>0.196795</td>\n",
       "      <td>-0.101786</td>\n",
       "      <td>0.570922</td>\n",
       "      <td>0.007743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>-0.316305</td>\n",
       "      <td>0.126331</td>\n",
       "      <td>0.084587</td>\n",
       "      <td>0.099225</td>\n",
       "      <td>-0.503260</td>\n",
       "      <td>-0.062559</td>\n",
       "      <td>0.115574</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.254925</td>\n",
       "      <td>-0.056957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514027</td>\n",
       "      <td>-0.316320</td>\n",
       "      <td>0.013955</td>\n",
       "      <td>-0.030025</td>\n",
       "      <td>-0.306975</td>\n",
       "      <td>0.139429</td>\n",
       "      <td>-0.256867</td>\n",
       "      <td>0.331288</td>\n",
       "      <td>-0.045333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>-0.342471</td>\n",
       "      <td>0.060391</td>\n",
       "      <td>-0.009947</td>\n",
       "      <td>0.156623</td>\n",
       "      <td>-0.511338</td>\n",
       "      <td>-0.070624</td>\n",
       "      <td>0.140290</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.275638</td>\n",
       "      <td>-0.068072</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595396</td>\n",
       "      <td>-0.419794</td>\n",
       "      <td>0.061882</td>\n",
       "      <td>-0.190783</td>\n",
       "      <td>-0.323777</td>\n",
       "      <td>0.185546</td>\n",
       "      <td>-0.144995</td>\n",
       "      <td>0.347215</td>\n",
       "      <td>-0.024521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>-0.379174</td>\n",
       "      <td>0.197136</td>\n",
       "      <td>0.149639</td>\n",
       "      <td>0.060261</td>\n",
       "      <td>-0.347212</td>\n",
       "      <td>-0.064022</td>\n",
       "      <td>0.119379</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>0.268377</td>\n",
       "      <td>-0.188386</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.517010</td>\n",
       "      <td>-0.354851</td>\n",
       "      <td>0.093440</td>\n",
       "      <td>-0.093673</td>\n",
       "      <td>-0.271739</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>-0.143179</td>\n",
       "      <td>0.410811</td>\n",
       "      <td>-0.105163</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>-0.379726</td>\n",
       "      <td>0.075891</td>\n",
       "      <td>0.100093</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>-0.429774</td>\n",
       "      <td>-0.140415</td>\n",
       "      <td>0.120826</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>0.154743</td>\n",
       "      <td>-0.030652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683223</td>\n",
       "      <td>-0.428964</td>\n",
       "      <td>0.052585</td>\n",
       "      <td>-0.172558</td>\n",
       "      <td>-0.218717</td>\n",
       "      <td>0.201938</td>\n",
       "      <td>-0.085569</td>\n",
       "      <td>0.345646</td>\n",
       "      <td>-0.032904</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>-0.279187</td>\n",
       "      <td>0.099571</td>\n",
       "      <td>0.229438</td>\n",
       "      <td>0.197775</td>\n",
       "      <td>-0.326235</td>\n",
       "      <td>-0.254882</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>0.034733</td>\n",
       "      <td>0.283212</td>\n",
       "      <td>-0.207798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574962</td>\n",
       "      <td>-0.275116</td>\n",
       "      <td>-0.012660</td>\n",
       "      <td>0.011353</td>\n",
       "      <td>-0.323538</td>\n",
       "      <td>0.055882</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.474825</td>\n",
       "      <td>-0.055474</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1034 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       embed_0   embed_1   embed_2   embed_3   embed_4   embed_5   embed_6  \\\n",
       "0    -0.089926  0.343874  0.176382  0.169358 -0.413337 -0.276315  0.188070   \n",
       "1     0.303261  0.084930  0.047369 -0.017244 -0.524733 -0.104934  0.335107   \n",
       "2    -0.274291  0.216801  0.029110  0.259279 -0.655594 -0.289643  0.073369   \n",
       "3     0.118676  0.095572  0.157358  0.225097 -0.632885 -0.125629  0.204013   \n",
       "4     0.298772  0.300674  0.366119 -0.022142 -0.748852 -0.035268  0.277504   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1029 -0.316305  0.126331  0.084587  0.099225 -0.503260 -0.062559  0.115574   \n",
       "1030 -0.342471  0.060391 -0.009947  0.156623 -0.511338 -0.070624  0.140290   \n",
       "1031 -0.379174  0.197136  0.149639  0.060261 -0.347212 -0.064022  0.119379   \n",
       "1032 -0.379726  0.075891  0.100093  0.118006 -0.429774 -0.140415  0.120826   \n",
       "1033 -0.279187  0.099571  0.229438  0.197775 -0.326235 -0.254882 -0.000509   \n",
       "\n",
       "       embed_7   embed_8   embed_9  ...  embed_375  embed_376  embed_377  \\\n",
       "0     0.094621  0.330203 -0.258730  ...  -0.272278  -0.230662   0.173143   \n",
       "1    -0.081476  0.213762 -0.105293  ...  -0.310262  -0.090271   0.129022   \n",
       "2     0.014463  0.104336 -0.014190  ...  -0.464926  -0.117493  -0.118993   \n",
       "3     0.074028  0.149310 -0.147779  ...  -0.030543  -0.100965   0.236099   \n",
       "4     0.075697  0.055439 -0.200804  ...  -0.149575  -0.230057   0.296528   \n",
       "...        ...       ...       ...  ...        ...        ...        ...   \n",
       "1029  0.012244  0.254925 -0.056957  ...  -0.514027  -0.316320   0.013955   \n",
       "1030  0.027731  0.275638 -0.068072  ...  -0.595396  -0.419794   0.061882   \n",
       "1031  0.019028  0.268377 -0.188386  ...  -0.517010  -0.354851   0.093440   \n",
       "1032  0.074879  0.154743 -0.030652  ...  -0.683223  -0.428964   0.052585   \n",
       "1033  0.034733  0.283212 -0.207798  ...  -0.574962  -0.275116  -0.012660   \n",
       "\n",
       "      embed_378  embed_379  embed_380  embed_381  embed_382  embed_383  \\\n",
       "0     -0.259786  -0.316996  -0.389919   0.105596   0.196438   0.117199   \n",
       "1     -0.008138  -0.220774  -0.021343  -0.029695   0.335977  -0.197539   \n",
       "2     -0.046860   0.010008  -0.118400  -0.085768   0.512956   0.023334   \n",
       "3     -0.286450  -0.130198  -0.051258  -0.047492   0.241473  -0.095162   \n",
       "4     -0.526185  -0.251471   0.196795  -0.101786   0.570922   0.007743   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "1029  -0.030025  -0.306975   0.139429  -0.256867   0.331288  -0.045333   \n",
       "1030  -0.190783  -0.323777   0.185546  -0.144995   0.347215  -0.024521   \n",
       "1031  -0.093673  -0.271739   0.042851  -0.143179   0.410811  -0.105163   \n",
       "1032  -0.172558  -0.218717   0.201938  -0.085569   0.345646  -0.032904   \n",
       "1033   0.011353  -0.323538   0.055882   0.001314   0.474825  -0.055474   \n",
       "\n",
       "      Classification  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1029               1  \n",
       "1030               1  \n",
       "1031               1  \n",
       "1032               1  \n",
       "1033               1  \n",
       "\n",
       "[1034 rows x 385 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae20d8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (827, 384) (827,)\n",
      "Testing set shape: (207, 384) (207,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "#Classification is the target variable. It contains the labels or outcomes you are trying to predict based on the features (X).\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)+\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "#X_train.shape: (827, 384) indicates there are 827 rows and 384 features (columns) in the training features.\n",
    "#y_train.shape: (827,) indicates 827 target values corresponding to the rows in X_train.\n",
    "#X_test.shape: (207, 384) indicates 207 rows and 384 features in the testing features.\n",
    "#y_test.shape: (207,) indicates 207 target values corresponding to the rows in X_test.\n",
    "\n",
    "#Training Set: Used to teach the model by allowing it to learn the relationships between features (X_train) and the target variable (y_train).\n",
    "#Testing Set: Used to evaluate the model's performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "721650f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 8\n",
      "Test Accuracy: 0.7246376811594203\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#Hyperparameters are parameters that are not learned by the model during training \n",
    "#but are set manually before the training process begins\n",
    "\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'n_neighbors': np.arange(1, 11)}\n",
    "\n",
    "# Create the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "#Using fewer folds (e.g., cv=2 or cv=3):Faster but may provide less reliable estimates.\n",
    "#Using more folds (e.g., cv=10 or higher):Provides more reliable estimates but increases computation time.\n",
    "\n",
    "\n",
    "# Fit the model43\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_k = grid_search.best_params_['n_neighbors']\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "final_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best k: {best_k}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf08af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7859733978234583\n",
      "Testing Accuracy: 0.7246376811594203\n",
      "F1 Score: 0.7238517036192456\n",
      "Precision: 0.7230999930656682\n",
      "Recall: 0.7246376811594203\n"
     ]
    }
   ],
   "source": [
    "#(KNN (K-Nearest Neighbors) is a simple, non-parametric supervised learning algorithm \n",
    "#used for classification and regression\n",
    "# Non-parametric models don't assume that the data follows any specific distribution\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the continuous target values to discrete classes\n",
    "y_train_classes = np.round(y_train)\n",
    "y_test_classes = np.round(y_test)\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=8)  \n",
    "\n",
    "# Train the KNN model on the training set\n",
    "knn_model.fit(X_train, y_train_classes)\n",
    "\n",
    "# Predict the output (classes) on the training set\n",
    "y_train_pred = knn_model.predict(X_train)\n",
    "\n",
    "# Predict the output (classes) on the testing set\n",
    "y_test_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the training set\n",
    "train_accuracy = accuracy_score(y_train_classes, y_train_pred)\n",
    "\n",
    "# Calculate accuracy on the testing set\n",
    "test_accuracy = accuracy_score(y_test_classes, y_test_pred)\n",
    "\n",
    "# Calculate F1 score, precision, and recall on the testing set\n",
    "f1 = f1_score(y_test_classes, y_test_pred, average='weighted')  # 'weighted' takes class imbalance into account\n",
    "precision = precision_score(y_test_classes, y_test_pred, average='weighted')\n",
    "recall = recall_score(y_test_classes, y_test_pred, average='weighted')\n",
    "\n",
    "# Display the results\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bafd67a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7318840579710144\n",
      "Mean F1 Score: 0.7149047366793011\n",
      "Mean Precision: 0.714629858188255\n",
      "Mean Recall: 0.7318840579710144\n",
      "Standard Deviation Accuracy: 0.02319343745730975\n",
      "Standard Deviation F1 Score: 0.024610261248219932\n",
      "Standard Deviation Precision: 0.02538862962701297\n",
      "Standard Deviation Recall: 0.02319343745730975\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "accuracy_list = []\n",
    "f1_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "# Set the number of iterations for random train-test splits\n",
    "num_iterations = 10\n",
    "\n",
    "# Run the model on multiple random train-test splits\n",
    "for _ in range(num_iterations):\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=np.random.randint(1, 100))\n",
    "\n",
    "    # Convert the continuous target values to discrete classes\n",
    "    y_train_classes = np.round(y_train)\n",
    "    y_test_classes = np.round(y_test)\n",
    "\n",
    "    # Initialize the KNN classifier\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "    # Train the KNN model on the training set\n",
    "    knn_model.fit(X_train, y_train_classes)\n",
    "\n",
    "    # Predict the output (classes) on the testing set\n",
    "    y_test_pred = knn_model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test_classes, y_test_pred)\n",
    "    f1 = f1_score(y_test_classes, y_test_pred, average='weighted')\n",
    "    precision = precision_score(y_test_classes, y_test_pred, average='weighted')\n",
    "    recall = recall_score(y_test_classes, y_test_pred, average='weighted')\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    accuracy_list.append(accuracy)\n",
    "    f1_list.append(f1)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "std_precision = np.std(precision_list)\n",
    "std_recall = np.std(recall_list)\n",
    "\n",
    "# Display the results\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean F1 Score:\", mean_f1)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "\n",
    "print(\"Standard Deviation Accuracy:\", std_accuracy)\n",
    "print(\"Standard Deviation F1 Score:\", std_f1)\n",
    "print(\"Standard Deviation Precision:\", std_precision)\n",
    "print(\"Standard Deviation Recall:\", std_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3013de8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Test Accuracy: 0.7729468599033816\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf'],   #rbf:radial basis function\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001]\n",
    "}\n",
    "#param_grid: A dictionary that defines the hyperparameters of the\n",
    "#Support Vector Machine (SVM) classifier that we want to tune.\n",
    "\n",
    "# Create the SVM classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_   #Retrieves the best hyperparameters found by the grid search.\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "final_model = SVC(**best_params)  #Creates a new SVC model using the best hyperparameters.\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6d44d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7654171704957679\n",
      "Testing Accuracy: 0.782608695652174\n",
      "F1 Score: 0.747911515619481\n",
      "Precision: 0.7748109640831757\n",
      "Recall: 0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Read the data from the Excel file\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_model = SVC(kernel='rbf', C=1.0)  # You can set the desired hyperparameters here\n",
    "\n",
    "# Train the SVM model on the training set\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the output on the training set\n",
    "y_train_pred = svm_model.predict(X_train)\n",
    "\n",
    "# Predict the output on the testing set\n",
    "y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate accuracy on the testing set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculate F1 score, precision, and recall on the testing set\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')  # 'weighted' takes class imbalance into account\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "# Display the results\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49f540f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7521739130434782\n",
      "Mean F1 Score: 0.6994897563938427\n",
      "Mean Precision: 0.7526735341015847\n",
      "Mean Recall: 0.7521739130434782\n",
      "Standard Deviation Accuracy: 0.023373855851986387\n",
      "Standard Deviation F1 Score: 0.03505564471430314\n",
      "Standard Deviation Precision: 0.03030597081159757\n",
      "Standard Deviation Recall: 0.023373855851986387\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Read the data from the Excel file\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "accuracy_list = []\n",
    "f1_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "# Set the number of iterations for random train-test splits\n",
    "num_iterations = 10\n",
    "\n",
    "# Run the SVM model on multiple random train-test splits\n",
    "for _ in range(num_iterations):\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=np.random.randint(1, 100))\n",
    "\n",
    "    # Initialize the SVM classifier\n",
    "    svm_model = SVC(kernel='rbf', C=1.0)\n",
    "\n",
    "    # Train the SVM model on the training set\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the output on the testing set\n",
    "    y_test_pred = svm_model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    accuracy_list.append(accuracy)\n",
    "    f1_list.append(f1)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "std_precision = np.std(precision_list)\n",
    "std_recall = np.std(recall_list)\n",
    "\n",
    "# Display the results\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean F1 Score:\", mean_f1)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "\n",
    "print(\"Standard Deviation Accuracy:\", std_accuracy)\n",
    "print(\"Standard Deviation F1 Score:\", std_f1)\n",
    "print(\"Standard Deviation Precision:\", std_precision)\n",
    "print(\"Standard Deviation Recall:\", std_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a60f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "Test Accuracy: 0.6763285024154589\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the data from the Excel file\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Decision Tree\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],  #gini: measures impurity of split \n",
    "                                       #entropy: measures reduction in entropy after a split\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create the Decision Tree classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(dt_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "final_model = DecisionTreeClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c713bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.939540507859734\n",
      "Testing Accuracy: 0.6811594202898551\n",
      "F1 Score: 0.6860340443612366\n",
      "Precision: 0.6919927133207591\n",
      "Recall: 0.6811594202898551\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from math import sqrt  # Add this import statement\n",
    "\n",
    "# Read the data from the Excel file\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier(criterion='entropy', max_depth=50, min_samples_split=10, min_samples_leaf=4, max_features='sqrt')\n",
    "\n",
    "# Train the Decision Tree model on the training set\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the output on the training set\n",
    "y_train_pred = dt_model.predict(X_train)\n",
    "\n",
    "# Predict the output on the testing set\n",
    "y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy on the training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate accuracy on the testing set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculate F1 score, precision, and recall on the testing set\n",
    "f1 = f1_score(y_test, y_test_pred, average='weighted')  # 'weighted' takes class imbalance into account\n",
    "precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "# Display the results\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f69db762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.6690821256038648\n",
      "Mean F1 Score: 0.6664828862927621\n",
      "Mean Precision: 0.6659753793759758\n",
      "Mean Recall: 0.6690821256038648\n",
      "Standard Deviation Accuracy: 0.049419605116123734\n",
      "Standard Deviation F1 Score: 0.04995152623662305\n",
      "Standard Deviation Precision: 0.05172054676452486\n",
      "Standard Deviation Recall: 0.049419605116123734\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Read the data from the Excel file\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "accuracy_list = []\n",
    "f1_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "# Set the number of iterations for random train-test splits\n",
    "num_iterations = 10\n",
    "\n",
    "# Run the Decision Tree model on multiple random train-test splits\n",
    "for _ in range(num_iterations):\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=np.random.randint(1, 100))\n",
    "\n",
    "    # Initialize the Decision Tree classifier\n",
    "    dt_model = DecisionTreeClassifier(criterion='entropy', max_depth=50, min_samples_split=10, min_samples_leaf=4, max_features='sqrt')\n",
    "\n",
    "    # Train the Decision Tree model on the training set\n",
    "    dt_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the output on the testing set\n",
    "    y_test_pred = dt_model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    accuracy_list.append(accuracy)\n",
    "    f1_list.append(f1)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "std_precision = np.std(precision_list)\n",
    "std_recall = np.std(recall_list)\n",
    "\n",
    "# Display the results+\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean F1 Score:\", mean_f1)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "\n",
    "print(\"Standard Deviation Accuracy:\", std_accuracy)\n",
    "print(\"Standard Deviation F1 Score:\", std_f1)\n",
    "print(\"Standard Deviation Precision:\", std_precision)\n",
    "print(\"Standard Deviation Recall:\", std_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a52f9695-c60b-455b-b0c3-e6bc14164f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Test Accuracy: 0.7536231884057971\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Read the data from the Excel file\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "    # Additional parameters for Random Forest can be added here\n",
    "}\n",
    "\n",
    "# Create the Random Forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create GridSearchCV object\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "final_model = RandomForestClassifier(**best_params)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6b6810d-7450-4368-b8bf-3a35c9d0f07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.729951690821256\n",
      "Mean F1 Score: 0.6932857008671435\n",
      "Mean Precision: 0.711469944080032\n",
      "Mean Recall: 0.729951690821256\n",
      "Standard Deviation Accuracy: 0.022290380666781302\n",
      "Standard Deviation F1 Score: 0.03246128373009588\n",
      "Standard Deviation Precision: 0.02049873351335967\n",
      "Standard Deviation Recall: 0.022290380666781302\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Read the data from the Excel file\n",
    "data = pd.read_excel('no_duplicates.xlsx')\n",
    "df1 = pd.DataFrame(data)\n",
    "\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df1.drop('Classification', axis=1)\n",
    "y = df1['Classification']\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "accuracy_list = []\n",
    "f1_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "\n",
    "# Set the number of iterations for random train-test splits\n",
    "num_iterations = 10\n",
    "\n",
    "# Run the Random Forest model on multiple random train-test splits\n",
    "for _ in range(num_iterations):\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=np.random.randint(1, 100))\n",
    "\n",
    "    # Initialize the Random Forest classifier\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # Train the Random Forest model on the training set\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the output on the testing set\n",
    "    y_test_pred = rf.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "\n",
    "    # Append metrics to the lists\n",
    "    accuracy_list.append(accuracy)\n",
    "    f1_list.append(f1)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "\n",
    "# Calculate mean and standard deviation for each metric\n",
    "mean_accuracy = np.mean(accuracy_list)\n",
    "mean_f1 = np.mean(f1_list)\n",
    "mean_precision = np.mean(precision_list)\n",
    "mean_recall = np.mean(recall_list)\n",
    "\n",
    "std_accuracy = np.std(accuracy_list)\n",
    "std_f1 = np.std(f1_list)\n",
    "std_precision = np.std(precision_list)\n",
    "std_recall = np.std(recall_list)\n",
    "\n",
    "# Display the results\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Mean F1 Score:\", mean_f1)\n",
    "print(\"Mean Precision:\", mean_precision)\n",
    "print(\"Mean Recall:\", mean_recall)\n",
    "\n",
    "print(\"Standard Deviation Accuracy:\", std_accuracy)\n",
    "print(\"Standard Deviation F1 Score:\", std_f1)\n",
    "print(\"Standard Deviation Precision:\", std_precision)\n",
    "print(\"Standard Deviation Recall:\", std_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535771c-b1e1-482f-93e6-136172d0136c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
